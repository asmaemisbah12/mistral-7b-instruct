llama-cpp-python>=0.2.0
fastapi>=0.100.0
uvicorn[standard]>=0.22.0
huggingface_hub>=0.20.0
